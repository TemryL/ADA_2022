{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All you need is love… And a pet!\n",
    "\n",
    "<img src=\"img/dataset-cover.jpg\" width=\"920\">\n",
    "\n",
    "Here we are going to build a classifier to predict whether an animal from an animal shelter will be adopted or not (aac_intakes_outcomes.csv, available at: https://www.kaggle.com/aaronschlegel/austin-animal-center-shelter-intakes-and-outcomes/version/1#aac_intakes_outcomes.csv). You will be working with the following features:\n",
    "\n",
    "1. *animal_type:* Type of animal. May be one of 'cat', 'dog', 'bird', etc.\n",
    "2. *intake_year:* Year of intake\n",
    "3. *intake_condition:* The intake condition of the animal. Can be one of 'normal', 'injured', 'sick', etc.\n",
    "4. *intake_number:* The intake number denoting the number of occurrences the animal has been brought into the shelter. Values higher than 1 indicate the animal has been taken into the shelter on more than one occasion.\n",
    "5. *intake_type:* The type of intake, for example, 'stray', 'owner surrender', etc.\n",
    "6. *sex_upon_intake:* The gender of the animal and if it has been spayed or neutered at the time of intake\n",
    "7. *age_upon\\_intake_(years):* The age of the animal upon intake represented in years\n",
    "8. *time_in_shelter_days:* Numeric value denoting the number of days the animal remained at the shelter from intake to outcome.\n",
    "9. *sex_upon_outcome:* The gender of the animal and if it has been spayed or neutered at time of outcome\n",
    "10. *age_upon\\_outcome_(years):* The age of the animal upon outcome represented in years\n",
    "11. *outcome_type:* The outcome type. Can be one of ‘adopted’, ‘transferred’, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from itertools import combinations \n",
    "import ast\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import seaborn as sn\n",
    "%matplotlib inline\n",
    "\n",
    "data_folder = './data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A) Load the dataset and convert categorical features to a suitable numerical representation (use dummy-variable encoding). \n",
    "- Split the data into a training set (80%) and a test set (20%). Pair each feature vector with the corresponding label, i.e., whether the outcome_type is adoption or not. \n",
    "- Standardize the values of each feature in the data to have mean 0 and variance 1.\n",
    "\n",
    "The use of external libraries is not permitted in part A, except for numpy and pandas. \n",
    "You can drop entries with missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['animal_type', 'intake_year', 'intake_condition', 'intake_number', 'intake_type', 'sex_upon_intake', \\\n",
    "            'age_upon_intake_(years)', 'time_in_shelter_days', 'sex_upon_outcome', 'age_upon_outcome_(years)', \\\n",
    "            'outcome_type']\n",
    "original_data = pd.read_csv(data_folder+'aac_intakes_outcomes.csv', usecols=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['animal_type', 'intake_year', 'intake_condition', 'intake_number', 'intake_type', 'sex_upon_intake', \\\n",
    "            'age_upon_intake_(years)', 'time_in_shelter_days', 'sex_upon_outcome', 'age_upon_outcome_(years)']\n",
    "\n",
    "X = original_data.dropna()[features]\n",
    "X = pd.get_dummies(X)\n",
    "y = original_data.dropna().outcome_type.apply(lambda x: 1 if x == 'Adoption' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "def train_test_split(X, y, train_ratio):\n",
    "    index = np.arange(len(X))\n",
    "    np.random.shuffle(index)\n",
    "    train_index = index[:int(train_ratio*len(index))]\n",
    "    test_index = index[int(train_ratio*len(index)):]\n",
    "    X_train = X.iloc[train_index]\n",
    "    y_train = y.iloc[train_index]\n",
    "    X_test = X.iloc[test_index]\n",
    "    y_test = y.iloc[test_index]\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "def standardize(X):\n",
    "    num_features = X[['age_upon_outcome_(years)', 'age_upon_intake_(years)', 'intake_year', 'intake_number', 'time_in_shelter_days']]\n",
    "    X[['age_upon_outcome_(years)', 'age_upon_intake_(years)', 'intake_year', 'intake_number', 'time_in_shelter_days']] = (num_features - num_features.mean())/num_features.std()\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = standardize(X)\n",
    "X_train, y_train, X_test, y_test = train_test_split(X, y, train_ratio=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B) Train a logistic regression classifier on your training set. Logistic regression returns probabilities as predictions, so in order to arrive at a binary prediction, you need to put a threshold on the predicted probabilities. \n",
    "- For the decision threshold of 0.5, present the performance of your classifier on the test set by displaying the confusion matrix. Based on the confusion matrix, manually calculate accuracy, precision, recall, and F1-score with respect to the positive and the negative class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_f1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/ada/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.3126975 , 0.6873025 ],\n",
       "       [0.42064784, 0.57935216],\n",
       "       [0.76604744, 0.23395256],\n",
       "       ...,\n",
       "       [0.66887854, 0.33112146],\n",
       "       [0.87202524, 0.12797476],\n",
       "       [0.91089183, 0.08910817]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C) Vary the value of the threshold in the range from 0 to 1 and visualize the value of accuracy, precision, recall, and F1-score (with respect to both classes) as a function of the threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D) Plot in a bar chart the coefficients of the logistic regression sorted by their contribution to the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Question 1: Which of the following metrics is most suitable when you are dealing with unbalanced classes?\n",
    "\n",
    "- a) F1 Score\n",
    "- b) Recall\n",
    "- c) Precision\n",
    "- d) Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: You are working on a binary classification problem. You trained a model on a training dataset and got the following confusion matrix on the test dataset. What is true about the evaluation metrics (rounded to the second decimal point):\n",
    "\n",
    "|            | Pred = NO|Pred=YES|\n",
    "|------------|----------|--------|\n",
    "| Actual NO  |    50    |   10   |\n",
    "| Actual YES |    5     |   100  |\n",
    "\n",
    "- a) Accuracy is 0.95\n",
    "- b) Accuracy is 0.85\n",
    "- c) False positive rate is 0.95\n",
    "- d) True positive rate is 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "93963d08e70ee6c5fda436d8fb318be1b3ce6c69e5c7a2a5023d39c7fdf62847"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
